{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing labels and imagery for use with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# takes a set of images and labels and prepares a structure that can be fed into\n",
    "# inception v3 (which can handle imagenet 2012 inputs)\n",
    "# this involves\n",
    "# finding the coordinates of labelled points and the corresponding image\n",
    "#  cropping at most 299 x 299 pixels around each labeled point.\n",
    "# storing each cropped image in directories named after the type of label\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/LZD1601/training_data/max-woodside already present - Skipping making dir\n"
     ]
    }
   ],
   "source": [
    "#training_path = '/Users/opizarro/training_data/max-woodside'\n",
    "training_path = '/Volumes/LZD1601/training_data/max-woodside'\n",
    "\n",
    "def maybe_makedir(dirname, force=False):\n",
    "  if os.path.isdir(dirname) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping making dir' % (dirname))\n",
    "  else:\n",
    "    print('Making dir %s.' % dirname)\n",
    "    os.makedirs(dirname)\n",
    "  return \n",
    "\n",
    "maybe_makedir(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#survey_sheet = '/Users/opizarro/max-woodside/QN01/MSA157-40_QN01.xls'\n",
    "#images_location = '/Users/opizarro/max-woodside/QN01/Stations'\n",
    "\n",
    "def process_sheet(survey_sheet, images_location):\n",
    "    df = pd.read_excel(survey_sheet)\n",
    "\n",
    "    df.head()\n",
    "#df.columns\n",
    "\n",
    "#for each row, \n",
    "#1)make a directory using Species label (if it doesn't exist already),\n",
    "#2)cut out the part of the image that corresponds to a 299x299 (at most) window around the X Y coords\n",
    "#3)save the cropped inmage into the corresponding directory\n",
    "    class_label_set = set(df['Species'])\n",
    "    print class_label_set\n",
    "    class_label_list = list(class_label_set)\n",
    "    print('Number of classes %i') % len(class_label_list)\n",
    "\n",
    "    for imclass in class_label_list:\n",
    "        maybe_makedir(os.path.join(training_path, imclass))\n",
    "    \n",
    "    image_set = set(df['PicName'])\n",
    "    suffix = '.JPG'\n",
    "    halfsize = (299-1)/2\n",
    "    image_list = list(image_set)\n",
    "    print(\"Number of images %i, number of entries %i\") % (len(image_list),len(df['PicName']))\n",
    "\n",
    "    prior_imagename = ''\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "    #print(row[1])\n",
    "    # read image\n",
    "        imagename = (row[1].PicName)+suffix\n",
    "        fullimagename = os.path.join(images_location,imagename)\n",
    "        #print(fullimagename)\n",
    "        if fullimagename != prior_imagename:\n",
    "            # only read image if its a different one from the one we've been using\n",
    "            image = cv2.imread(os.path.join(images_location,imagename))\n",
    "            #print image.shape\n",
    "            prior_imagename = fullimagename\n",
    "        \n",
    "    \n",
    "        #cv2.imshow(\"original\",image)\n",
    "        #plt.figure(1)\n",
    "        #plt.imshow(image)\n",
    "        # read label\n",
    "        imlabel = row[1].Species\n",
    "        #print ('entry %s has label %s') % (imagename, imlabel)\n",
    "   \n",
    "   \n",
    "        # find centre points\n",
    "        x = row[1][9]\n",
    "        y = row[1][10]\n",
    "        xdim = row[1][3]\n",
    "        ydim = row[1][4]\n",
    "        #print('x %i, y %i, xdim %i, ydim %i') % (x,y,xdim,ydim)\n",
    "        # check dimensions correpond\n",
    "        if xdim != image.shape[1] or ydim !=image.shape[0]:\n",
    "            print('WARNING: actual image size and size in database not consistent')\n",
    "    \n",
    "    \n",
    "        # draw circle\n",
    "        #cv2.circle(image,(x,y),11,(0,255,0),-1)\n",
    "    \n",
    "        # crop around centre point\n",
    "        dx = min(min(x,halfsize),min(halfsize,xdim-x));\n",
    "        dy = min(min(y,halfsize),min(halfsize,ydim-y));\n",
    "        hs = min(dx,dy)\n",
    "        # at least 81 pixels across to have some context\n",
    "        if hs > 40 : \n",
    "            crop_image = image[y-hs:y+hs, x-hs:x+hs]\n",
    "        \n",
    "            # save cropped image in corresponding directory\n",
    "            crop_name = row[1].PicName + '_' + str(x) + '_' + str(y) + '.jpg'\n",
    "            fullcrop_name = os.path.join(training_path,imlabel,crop_name)\n",
    "            cv2.imwrite(fullcrop_name,crop_image)\n",
    "    \n",
    "            if 0 and imlabel != 'Sand' and imlabel != 'Turf':\n",
    "                cutstr =  ('this dot %s has label %s') % (imagename, imlabel)\n",
    "                titstr =  ('x %i, y %i, xdim %i, ydim %i, hs %i') % (x,y,xdim,ydim,hs)\n",
    "                plt.figure(1)\n",
    "                plt.imshow(image)\n",
    "                plt.title(titstr)\n",
    "                plt.figure(2)\n",
    "                plt.imshow(crop_image)\n",
    "                plt.title(cutstr)\n",
    "        \n",
    "            if row[0]%1000 == 0:\n",
    "                print(\"processing entry \" + str(row[0]) + \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/LZD1601/max-woodside/QN05/MSA157-40_QN05.xlsx\n",
      "set([u'Halophila spinulosa', u'Unknown', u'Turbinaria', u'Padina', u'Upright Fauna', u'Halophila', u'Halimeda', u'Non-Coral Fauna', u'Green Alga', u'Faviid', u'RedBrown Alga', u'Seagrass', u'Flora', u'Mobile', u'Sand', u'Rock', u'Turf', u'Alga', u'Ascidian', u'Rubble', u'Soft Coral', u'Sponge', u'Porites', u'Gorgonian', u'Foraminifera'])\n",
      "Number of classes 25\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halophila spinulosa already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Unknown already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Turbinaria already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Padina already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Upright Fauna already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halophila already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halimeda already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Non-Coral Fauna already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Green Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Faviid already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/RedBrown Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Seagrass already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Flora already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Mobile already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Sand already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Rock already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Turf already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Ascidian already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Rubble already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Soft Coral already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Sponge already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Porites already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Gorgonian already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Foraminifera already present - Skipping making dir\n",
      "Number of images 980, number of entries 24500\n",
      "processing entry 1000\n",
      "processing entry 2000\n",
      "processing entry 3000\n",
      "processing entry 4000\n",
      "processing entry 5000\n",
      "processing entry 6000\n",
      "processing entry 7000\n",
      "processing entry 8000\n",
      "processing entry 9000\n",
      "processing entry 10000\n",
      "processing entry 11000\n",
      "processing entry 12000\n",
      "processing entry 13000\n",
      "processing entry 14000\n",
      "processing entry 15000\n",
      "processing entry 16000\n",
      "processing entry 18000\n",
      "processing entry 19000\n",
      "processing entry 21000\n",
      "processing entry 22000\n",
      "processing entry 23000\n",
      "processing entry 24000\n",
      "/Volumes/LZD1601/max-woodside/QN07/MSA157-40_QN07.xlsx\n",
      "set([u'Bryozoan', u'Halophila spinulosa', u'Unknown', u'Turbinaria', u'Padina', u'Upright Fauna', u'Halophila', u'Halimeda', u'Non-Coral Fauna', u'Green Alga', u'RedBrown Alga', u'Seagrass', u'Flora', u'Mobile', u'Sand', u'Turf', u'Alga', u'Ascidian', u'Rubble', u'Soft Coral', u'Sponge', u'Gorgonian'])\n",
      "Number of classes 22\n",
      "/Volumes/LZD1601/training_data/max-woodside/Bryozoan already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halophila spinulosa already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Unknown already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Turbinaria already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Padina already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Upright Fauna already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halophila already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halimeda already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Non-Coral Fauna already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Green Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/RedBrown Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Seagrass already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Flora already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Mobile already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Sand already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Turf already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Ascidian already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Rubble already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Soft Coral already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Sponge already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Gorgonian already present - Skipping making dir\n",
      "Number of images 825, number of entries 20625\n",
      "processing entry 0\n",
      "processing entry 1000\n",
      "processing entry 2000\n",
      "processing entry 3000\n",
      "processing entry 4000\n",
      "processing entry 5000\n",
      "processing entry 6000\n",
      "processing entry 7000\n",
      "processing entry 8000\n",
      "processing entry 10000\n",
      "processing entry 11000\n",
      "processing entry 12000\n",
      "processing entry 13000\n",
      "processing entry 14000\n",
      "processing entry 15000\n",
      "processing entry 16000\n",
      "processing entry 17000\n",
      "processing entry 18000\n",
      "/Volumes/LZD1601/max-woodside/QN06/MSA157-40_QN06.xlsx\n",
      "set([u'Bryozoan', u'Halophila spinulosa', u'Unknown', u'Turbinaria', u'Other', u'Upright Fauna', u'Padina', u'Halophila', u'Halimeda', u'Non-Coral Fauna', u'Green Alga', u'RedBrown Alga', u'Seagrass', u'Mobile', u'Sand', u'Turf', u'Alga', u'Ascidian', u'Rubble', u'Soft Coral', u'Sponge', u'Porites', u'Gorgonian'])\n",
      "Number of classes 23\n",
      "/Volumes/LZD1601/training_data/max-woodside/Bryozoan already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halophila spinulosa already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Unknown already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Turbinaria already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Other already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Upright Fauna already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Padina already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halophila already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Halimeda already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Non-Coral Fauna already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Green Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/RedBrown Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Seagrass already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Mobile already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Sand already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Turf already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Alga already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Ascidian already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Rubble already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Soft Coral already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Sponge already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Porites already present - Skipping making dir\n",
      "/Volumes/LZD1601/training_data/max-woodside/Gorgonian already present - Skipping making dir\n",
      "Number of images 812, number of entries 20300\n",
      "processing entry 0\n",
      "processing entry 1000\n",
      "processing entry 2000\n",
      "processing entry 3000\n",
      "processing entry 4000\n",
      "processing entry 5000\n",
      "processing entry 6000\n",
      "processing entry 7000\n",
      "processing entry 8000\n",
      "processing entry 9000\n",
      "processing entry 10000\n",
      "processing entry 14000\n",
      "processing entry 15000\n",
      "processing entry 16000\n",
      "processing entry 18000\n",
      "processing entry 19000\n",
      "processing entry 20000\n"
     ]
    }
   ],
   "source": [
    "#survey_sheet = '/Users/opizarro/max-woodside/QN01/MSA157-40_QN01.xls'\n",
    "#images_location = '/Users/opizarro/max-woodside/QN01/Stations'\n",
    "# QN02 has a different directory and file structure\n",
    "# QN08 has the same images as QN09 with the names of QN09\n",
    "#transects = {'QN01','QN03','QN04','QN05','QN06','QN07','QN08','QN09','QN10','QN11','QN12'}\n",
    "#transects = {'QN03','QN05','QN06','QN07','QN08','QN09','QN10','QN11','QN12'}\n",
    "transects = {'QN05','QN06','QN07'}\n",
    "for tr in transects:\n",
    "    survey_sheet = '/Volumes/LZD1601/max-woodside/' + tr + '/MSA157-40_' + tr + '.xlsx'\n",
    "    images_location = '/Volumes/LZD1601/max-woodside/' + tr + '/Stations'\n",
    "    print survey_sheet\n",
    "    process_sheet(survey_sheet, images_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
